import { useEffect, useRef, useState } from "react";
import { motion } from "motion/react";
import { Progress } from "../ui/progress";
import { X } from "lucide-react";

// =========================================
// CONFIG
// =========================================
interface FaceScanScreenProps {
  onAnalyzeResult: (result: any) => void;
  onBack: () => void;
}

const STEPS = ["‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏á", "‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢", "‡∏´‡∏±‡∏ô‡∏Ç‡∏ß‡∏≤"] as const;
type Step = 0 | 1 | 2;

const STABLE_TIME = 3000;      // ‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡πà‡∏á‡∏Å‡∏µ‡πà‡∏°‡∏¥‡∏•‡∏•‡∏¥‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (3 ‡∏ß‡∏¥)
const CAPTURE_INTERVAL = 500;  // ‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏∏‡∏Å 0.5 ‡∏ß‡∏¥

const API_BASE =
  import.meta.env.VITE_API_BASE ||
  "https://aishincarebackend-production.up.railway.app";

// =========================================
// COMPONENT
// =========================================
export function FaceScanScreen({ onAnalyzeResult, onBack }: FaceScanScreenProps) {
  const videoRef = useRef<HTMLVideoElement>(null);

  // UI state
  const [step, setStep] = useState<Step>(0);       // 0=front, 1=left, 2=right
  const [thumbs, setThumbs] = useState<string[]>([]);
  const [status, setStatus] = useState("üì∑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á...");
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [progress, setProgress] = useState(0);
  const [stablePercent, setStablePercent] = useState(0);

  // pose/lighting indicators
  const [faceOk, setFaceOk] = useState(false);
  const [lightOk, setLightOk] = useState(true);

  // control flags (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const startStableTime = useRef<number | null>(null); // ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ô‡∏¥‡πà‡∏á
  const loopRunning = useRef(false);                   // ‡∏Å‡∏±‡∏ô loop ‡∏ã‡πâ‡∏≠‡∏ô (fetch ‡∏ã‡πâ‡∏≠‡∏ô)
  const stepLocked  = useRef(false);                   // ‡∏Å‡∏±‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ã‡πâ‡∏≥ (‡∏´‡∏•‡∏±‡∏á‡∏Ñ‡∏£‡∏ö‡πÄ‡∏ß‡∏•‡∏≤)

  // ========== ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á + ‡πÄ‡∏£‡∏¥‡πà‡∏° loop ==========
  useEffect(() => {
    (async () => {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        await videoRef.current.play();
      }
      setStatus(`üì∑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[0]}`);
      timerRef.current = setInterval(loop, CAPTURE_INTERVAL);
    })();

    return () => {
      if (timerRef.current) clearInterval(timerRef.current);
    };
  }, []);

  // ========== ‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô Blob ==========
  async function captureFrame(): Promise<Blob | null> {
    const v = videoRef.current!;
    if (!v || v.videoWidth === 0 || v.videoHeight === 0) return null;

    const c = document.createElement("canvas");
    c.width = v.videoWidth;
    c.height = v.videoHeight;
    const ctx = c.getContext("2d")!;
    // ‡∏Å‡∏£‡∏∞‡∏à‡∏Å (mirror) ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤
    ctx.translate(c.width, 0);
    ctx.scale(-1, 1);
    ctx.drawImage(v, 0, 0, c.width, c.height);

    return await new Promise((resolve) =>
      c.toBlob((b) => resolve(b), "image/jpeg", 0.8)
    );
  }

  // ========== LOOP ‡∏ï‡∏£‡∏ß‡∏à‡∏°‡∏∏‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå (‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≠‡∏ô/‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥) ==========
  async function loop() {
    // ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏≠/‡∏ñ‡πà‡∏≤‡∏¢/‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏∏‡∏°‡∏≠‡∏¢‡∏π‡πà ‚Üí ‡∏≠‡∏¢‡πà‡∏≤‡∏£‡∏±‡∏ô‡∏ã‡πâ‡∏≥
    if (loopRunning.current || stepLocked.current) return;
    loopRunning.current = true;

    const blob = await captureFrame();
    if (!blob) {
      loopRunning.current = false;
      return;
    }

    const formData = new FormData();
    formData.append("file", blob, "frame.jpg");

    try {
      const res = await fetch(`${API_BASE}/analyze/pose`, {
        method: "POST",
        body: formData,
      });
      const data = await res.json();

      // normalize pose
      let pose = "";
      if (Array.isArray(data.pose)) pose = String(data.pose[0]).trim().toLowerCase();
      else if (typeof data.pose === "string")
        pose = data.pose.split(",")[0].replace(/[\(\)']/g, "").trim().toLowerCase();

      const target = step === 0 ? "front" : step === 1 ? "left" : "right";

      // update indicators
      setFaceOk(!!data.face_ok);
      setLightOk(!!data.light_ok);

      // guard: ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏´‡∏ô‡πâ‡∏≤/‡πÅ‡∏™‡∏á‡πÑ‡∏°‡πà‡∏û‡∏≠ ‚Üí reset ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞ progress
      if (!data.face_ok) {
        setStatus("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á");
        startStableTime.current = null;
        setStablePercent(0);
        loopRunning.current = false;
        return;
      }
      if (!data.light_ok) {
        setStatus("üí° ‡πÅ‡∏™‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á");
        startStableTime.current = null;
        setStablePercent(0);
        loopRunning.current = false;
        return;
      }

      // ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
      if (pose === target) {
        if (!startStableTime.current) startStableTime.current = Date.now();

        const elapsed = Date.now() - startStableTime.current;
        setStablePercent(Math.min((elapsed / STABLE_TIME) * 100, 100));
        setStatus(`‚úÖ ${STEPS[step]} ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (${(elapsed / 1000).toFixed(1)}s / ${STABLE_TIME / 1000}s)`);

        // ‡∏Ñ‡∏£‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏¥‡πà‡∏á ‚Üí ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        if (elapsed >= STABLE_TIME) {
          // ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¢‡∏π‡πà (‡∏£‡∏≠‡∏ö‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤) ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏•‡∏¢
          if (stepLocked.current) {
            loopRunning.current = false;
            return;
          }

          // üîí ‡∏•‡πá‡∏≠‡∏Å‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
          stepLocked.current = true;
          loopRunning.current = true;
          startStableTime.current = null;

          // ‡∏´‡∏¢‡∏∏‡∏î loop ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏∏‡∏Å‡∏£‡∏≠‡∏ö
          if (timerRef.current) {
            clearInterval(timerRef.current);
            timerRef.current = null;
          }

          // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û + reset progress
          captureThumb();
          setStablePercent(0);
          setStatus(`üì∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏°‡∏∏‡∏° ${STEPS[step]} ‡πÅ‡∏•‡πâ‡∏ß!`);

          // ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° 1.2 ‡∏ß‡∏¥ ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡πÉ‡∏´‡∏°‡πà
          setTimeout(() => {
            nextStep();

            // ‡∏õ‡∏•‡∏î‡∏•‡πá‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏° loop ‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏°‡∏∏‡∏°‡πÉ‡∏´‡∏°‡πà
            stepLocked.current = false;
            loopRunning.current = false;

            if (!timerRef.current) {
              timerRef.current = setInterval(loop, CAPTURE_INTERVAL);
            }
          }, 1200);
        }
      } else {
        // ‡∏°‡∏∏‡∏°‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á ‚Üí reset timer & progress
        startStableTime.current = null;
        setStablePercent(0);
        setStatus(`üü° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[step]}‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏° (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠: ${pose || "‡πÑ‡∏°‡πà‡∏û‡∏ö"})`);
      }
    } catch (err) {
      console.error("Pose analyze failed:", err);
    }

    loopRunning.current = false;
  }

  // ========== ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dataURL ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô thumbs) ==========
  function captureThumb() {
    const v = videoRef.current!;
    const c = document.createElement("canvas");
    c.width = v.videoWidth;
    c.height = v.videoHeight;
    const ctx = c.getContext("2d")!;
    ctx.translate(c.width, 0);
    ctx.scale(-1, 1);
    ctx.drawImage(v, 0, 0, c.width, c.height);
    setThumbs((t) => [...t, c.toDataURL("image/jpeg")]);
  }

  // ========== ‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ / ‡∏Ñ‡∏£‡∏ö 3 ‡∏°‡∏∏‡∏°‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ==========
  function nextStep() {
    if (step < 2) {
      const next = (step + 1) as Step;
      setStep(next);
      setStatus(`‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏ï‡πà‡∏≠‡πÑ‡∏õ: ${STEPS[next]}`);
    } else {
      if (timerRef.current) clearInterval(timerRef.current);
      setStatus("üéâ ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 3 ‡∏°‡∏∏‡∏°‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß...");
      startAnalyze();
    }
  }

  // ========== ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ==========
  async function startAnalyze() {
    setIsAnalyzing(true);

    // dataURL ‚Üí Blob ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á
    const blobs = await Promise.all(thumbs.map((t) => fetch(t).then((r) => r.blob())));
    const formData = new FormData();
    blobs.forEach((b, i) => formData.append("files", b, `angle_${i}.jpg`));

    const res = await fetch(`${API_BASE}/analyze/skin`, { method: "POST", body: formData });
    const data = await res.json();

    // ‡πÅ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô progress (fake progress ‡∏™‡∏ß‡∏¢ ‡πÜ)
    let p = 0;
    const t = setInterval(() => {
      p += 5;
      setProgress(p);
      if (p >= 100) {
        clearInterval(t);
        onAnalyzeResult(data);
      }
    }, 80);
  }

  // ========== ‡∏™‡∏µ‡∏Å‡∏£‡∏≠‡∏ö‡∏ß‡∏á‡∏£‡∏µ ==========
  const borderColor = !faceOk
    ? "border-pink-300"
    : lightOk
    ? "border-pink-500 shadow-[0_0_25px_rgba(244,114,182,0.8)]"
    : "border-yellow-400";

  // ========== UI ==========
  return (
    <div className="min-h-screen bg-black relative overflow-hidden">
      {/* Back */}
      <button
        onClick={onBack}
        className="absolute top-6 left-6 z-20 w-10 h-10 bg-black/30 rounded-full flex items-center justify-center"
      >
        <X className="w-6 h-6 text-white" />
      </button>

      {/* Camera */}
      <video
        ref={videoRef}
        className="absolute inset-0 w-full h-full object-cover transform -scale-x-100"
        autoPlay
        muted
        playsInline
      />

      {/* Face ellipse */}
      <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
        <div className={`w-72 h-96 rounded-full border-4 transition-all duration-150 ${borderColor}`} />
      </div>

      {/* Status */}
      <motion.div
        className="absolute top-20 w-full text-center z-20 px-4"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
      >
        <div className="bg-black/60 text-white px-5 py-3 rounded-2xl inline-block text-lg font-medium">
          {status}
        </div>
      </motion.div>

      {/* Stable progress (‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πà‡∏á 3 ‡∏ß‡∏¥) */}
      {!isAnalyzing && stablePercent > 0 && (
        <div className="absolute bottom-24 w-full flex justify-center z-20">
          <div className="w-2/3">
            <Progress value={stablePercent} className="h-2" />
          </div>
        </div>
      )}

      {/* Analyze overlay */}
      {isAnalyzing && (
        <motion.div
          className="absolute inset-0 flex flex-col items-center justify-center bg-black/80 z-30"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
        >
          <div className="text-white mb-6 text-xl font-semibold">üî¨ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...</div>
          <Progress value={progress} className="h-3 w-3/4 mb-3" />
          <div className="text-pink-300 text-lg">{progress}%</div>
        </motion.div>
      )}

      {/* Thumbnails */}
      <div className="absolute bottom-8 w-full flex justify-center gap-4 z-10">
        {thumbs.map((img, i) => (
          <img
            key={i}
            src={img}
            className="w-20 h-20 object-cover rounded-full border-2 border-pink-400 shadow-md"
          />
        ))}
      </div>
    </div>
  );
}
