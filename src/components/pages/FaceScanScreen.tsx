// src/components/pages/FaceScanScreen.tsx
import { useEffect, useRef, useState } from "react";
import { motion } from "motion/react";
import { Progress } from "../ui/progress";
import { X } from "lucide-react";

// === Mediapipe FaceMesh ===
import { FaceMesh } from "@mediapipe/face_mesh";
import { Camera } from "@mediapipe/camera_utils";
import {
  drawConnectors,
  drawLandmarks,
} from "@mediapipe/drawing_utils";

// -----------------------------------------
// CONFIG
// -----------------------------------------
interface FaceScanScreenProps {
  onAnalyzeResult: (result: any) => void;
  onBack: () => void;
}

const STEPS = ["‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏á", "‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢", "‡∏´‡∏±‡∏ô‡∏Ç‡∏ß‡∏≤"] as const;
type Step = 0 | 1 | 2;

const STABLE_TIME = 3000;   // ‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡πà‡∏á 3 ‡∏ß‡∏¥
const NEXT_DELAY = 700;     // ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏ô‡πà‡∏ß‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏°‡∏∏‡∏°‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
const FACE_WIDTH_MIN = 0.28; // ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡πÄ‡∏ü‡∏£‡∏°‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î (‡∏Å‡∏±‡∏ô‡πÑ‡∏Å‡∏•‡πÑ‡∏õ)
const API_BASE =
  import.meta.env.VITE_API_BASE ||
  "https://aishincarebackend-production.up.railway.app";

// -----------------------------------------
// COMPONENT
// -----------------------------------------
export function FaceScanScreen({ onAnalyzeResult, onBack }: FaceScanScreenProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);

  // UI state
  const [step, setStep] = useState<Step>(0);
  const [thumbs, setThumbs] = useState<string[]>([]);
  const [status, setStatus] = useState("üì∑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á...");
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [progress, setProgress] = useState(0);
  const [stablePercent, setStablePercent] = useState(0);

  // control flags
  const startStableTime = useRef<number | null>(null);
  const stepLocked = useRef(false);                // ‡∏Å‡∏±‡∏ô‡∏ñ‡πà‡∏≤‡∏¢‡∏ã‡πâ‡∏≥
  const capturedSteps = useRef<Set<number>>(new Set()); // ‡∏Å‡∏±‡∏ô‡∏°‡∏∏‡∏°‡∏•‡∏∞‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ
  const faceMeshRef = useRef<FaceMesh | null>(null);
  const cameraRef = useRef<Camera | null>(null);

  // =========================================
  // üß† Setup Mediapipe FaceMesh + Camera
  // =========================================
  useEffect(() => {
    const faceMesh = new FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.6,
    });

    faceMesh.onResults(onResults);
    faceMeshRef.current = faceMesh;

    // ‡∏Å‡∏•‡πâ‡∏≠‡∏á
    const v = videoRef.current!;
    const cam = new Camera(v, {
      onFrame: async () => {
        // ‡∏™‡πà‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏Ç‡πâ‡∏≤ Mediapipe ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ü‡∏£‡∏°
        await faceMesh.send({ image: v });
      },
      width: 640,
      height: 480,
    });
    cam.start();
    cameraRef.current = cam;

    setStatus(`üì∑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[0]}`);

    // cleanup
    return () => {
      try {
        cameraRef.current?.stop();
      } catch {}
      faceMeshRef.current?.close();
      faceMeshRef.current = null;
      cameraRef.current = null;
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // =========================================
  // üß™ ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏°‡∏∏‡∏°‡∏à‡∏≤‡∏Å FaceMesh ‡πÅ‡∏•‡∏∞‡∏ß‡∏≤‡∏î overlay
  // =========================================
  function onResults(results: any) {
    const canvas = canvasRef.current!;
    const ctx = canvas.getContext("2d")!;
    // sync ‡∏Ç‡∏ô‡∏≤‡∏î canvas ‡∏Å‡∏±‡∏ö‡∏ß‡∏µ‡∏î‡∏¥‡πÇ‡∏≠‡∏à‡∏£‡∏¥‡∏á
    if (videoRef.current) {
      const { videoWidth, videoHeight } = videoRef.current;
      if (canvas.width !== videoWidth || canvas.height !== videoHeight) {
        canvas.width = videoWidth;
        canvas.height = videoHeight;
      }
    }

    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
      // ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ‚Üí reset progress
      startStableTime.current = null;
      setStablePercent(0);
      setStatus("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Ç‡∏¢‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á");
      return;
    }

    const landmarks = results.multiFaceLandmarks[0];

    // ‡∏ß‡∏≤‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡∏™‡∏ß‡∏¢ ‡πÜ)
    drawConnectors(ctx, landmarks, FaceMesh.FACEMESH_TESSELATION, {
      color: "rgba(255,153,204,0.7)",
      lineWidth: 0.5,
    });
    drawLandmarks(ctx, landmarks, {
      color: "rgba(255,255,255,0.8)",
      lineWidth: 0.5,
      radius: 0.5,
    });

    // ===== ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì "‡∏°‡∏∏‡∏°" ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á landmark =====
    // ‡πÉ‡∏ä‡πâ‡∏´‡∏π‡∏ã‡πâ‡∏≤‡∏¢(234) ‡∏´‡∏π‡∏Ç‡∏ß‡∏≤(454) ‡πÅ‡∏•‡∏∞‡∏à‡∏°‡∏π‡∏Å(1)
    const leftEar = landmarks[234];
    const rightEar = landmarks[454];
    const nose = landmarks[1];

    // ‡∏Å‡∏±‡∏ô‡πÄ‡∏Ñ‡∏™‡∏†‡∏≤‡∏û‡πÄ‡∏•‡πá‡∏Å/‡∏´‡∏°‡∏∏‡∏ô ‚Äî ‡πÉ‡∏ä‡πâ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏Å‡∏ô X (normalized 0..1)
    const faceWidth = Math.abs(rightEar.x - leftEar.x);
    if (faceWidth < FACE_WIDTH_MIN) {
      startStableTime.current = null;
      setStablePercent(0);
      setStatus("üìè ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏ô‡∏¥‡∏î");
      return;
    }

    // ratio: ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏°‡∏π‡∏Å‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏™‡πâ‡∏ô‡∏´‡∏π‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤
    const ratio = (nose.x - leftEar.x) / (rightEar.x - leftEar.x);

    let pose: "front" | "left" | "right" = "front";
    if (ratio < 0.35) pose = "left";
    else if (ratio > 0.65) pose = "right";

    const target: "front" | "left" | "right" =
      step === 0 ? "front" : step === 1 ? "left" : "right";

    // ===== ‡∏•‡πá‡∏≠‡∏Å‡∏°‡∏∏‡∏°: ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∏‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô =====
    if (pose === target) {
      if (!startStableTime.current) startStableTime.current = Date.now();
      const elapsed = Date.now() - startStableTime.current;
      setStablePercent(Math.min((elapsed / STABLE_TIME) * 100, 100));
      setStatus(`‚úÖ ${STEPS[step]} ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (${(elapsed / 1000).toFixed(1)}s / 3s)`);

      // ‡∏Ñ‡∏£‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢ capture ‡∏°‡∏∏‡∏°‡∏ô‡∏µ‡πâ
      if (elapsed >= STABLE_TIME && !stepLocked.current && !capturedSteps.current.has(step)) {
        stepLocked.current = true; // ‡∏Å‡∏±‡∏ô‡∏ñ‡πà‡∏≤‡∏¢‡∏ã‡πâ‡∏≥‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        capturedSteps.current.add(step);

        captureThumb();           // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        setStablePercent(0);
        setStatus(`üì∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏°‡∏∏‡∏° ${STEPS[step]} ‡πÅ‡∏•‡πâ‡∏ß!`);

        // ‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        setTimeout(() => {
          handleNextStep();
        }, NEXT_DELAY);
      }
    } else {
      // ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏°‡∏∏‡∏° ‚Üí reset ‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
      startStableTime.current = null;
      setStablePercent(0);
      setStatus(`üü° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[step]}‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏°`);
    }
  }

  // =========================================
  // ‚è≠Ô∏è ‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ / ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
  // =========================================
  function handleNextStep() {
    if (step < 2) {
      const next = (step + 1) as Step;
      setStep(next);
      setStatus(`üü° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[next]}‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏°`);
      startStableTime.current = null;
      setStablePercent(0);
      stepLocked.current = false; // ‡∏õ‡∏•‡∏î‡∏•‡πá‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏°‡∏∏‡∏°‡πÉ‡∏´‡∏°‡πà
    } else {
      setStatus("üéâ ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 3 ‡∏°‡∏∏‡∏°‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß...");
      startAnalyze();
    }
  }

  // =========================================
  // üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡∏°‡∏∏‡∏°‡∏•‡∏∞ 1 ‡∏£‡∏π‡∏õ)
  // =========================================
  function captureThumb() {
    const v = videoRef.current!;
    if (!v || v.videoWidth === 0 || v.videoHeight === 0) return;
    const c = document.createElement("canvas");
    c.width = v.videoWidth;
    c.height = v.videoHeight;
    const ctx = c.getContext("2d")!;
    // ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤ ‚Üí mirror
    ctx.translate(c.width, 0);
    ctx.scale(-1, 1);
    ctx.drawImage(v, 0, 0, c.width, c.height);
    const dataURL = c.toDataURL("image/jpeg", 0.9);
    setThumbs((t) => {
      // safety: ‡∏°‡∏∏‡∏°‡∏•‡∏∞‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
      if (t.length <= step) return [...t, dataURL];
      return t;
    });
  }

  // =========================================
  // üî¨ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß (‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ 3 ‡∏°‡∏∏‡∏°)
  // =========================================
  async function startAnalyze() {
    setIsAnalyzing(true);

    // dataURL -> Blob
    const blobs = await Promise.all(
      thumbs.map((t) => fetch(t).then((r) => r.blob()))
    );
    const formData = new FormData();
    blobs.forEach((b, i) => formData.append("files", b, `angle_${i}.jpg`));

    const res = await fetch(`${API_BASE}/analyze/skin`, {
      method: "POST",
      body: formData,
    });
    const data = await res.json();

    // fake progress ‡∏™‡∏ß‡∏¢ ‡πÜ
    let p = 0;
    const timer = setInterval(() => {
      p += 5;
      setProgress(p);
      if (p >= 100) {
        clearInterval(timer);
        onAnalyzeResult(data);
      }
    }, 80);
  }

  // =========================================
  // UI
  // =========================================
  return (
    <div className="min-h-screen bg-black relative overflow-hidden">
      {/* Back */}
      <button
        onClick={onBack}
        className="absolute top-6 left-6 z-20 w-10 h-10 bg-black/30 rounded-full flex items-center justify-center"
      >
        <X className="w-6 h-6 text-white" />
      </button>

      {/* Camera */}
      <video
        ref={videoRef}
        className="absolute inset-0 w-full h-full object-cover transform -scale-x-100"
        autoPlay
        muted
        playsInline
      />
      {/* FaceMesh overlay */}
      <canvas
        ref={canvasRef}
        className="absolute inset-0 w-full h-full pointer-events-none"
        style={{
          filter: "drop-shadow(0 0 10px rgba(255,105,180,0.6))",
        }}
      />

      {/* Status */}
      <motion.div
        className="absolute top-20 w-full text-center z-20 px-4"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
      >
        <div className="bg-black/60 text-white px-5 py-3 rounded-2xl inline-block text-lg font-medium">
          {status}
        </div>
      </motion.div>

      {/* Stable Progress */}
      {!isAnalyzing && stablePercent > 0 && (
        <div className="absolute bottom-24 w-full flex justify-center z-20">
          <div className="w-2/3">
            <Progress value={stablePercent} className="h-2" />
          </div>
        </div>
      )}

      {/* Analyze Overlay */}
      {isAnalyzing && (
        <motion.div
          className="absolute inset-0 flex flex-col items-center justify-center bg-black/80 z-30"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
        >
          <div className="text-white mb-6 text-xl font-semibold">
            üî¨ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...
          </div>
          <Progress value={progress} className="h-3 w-3/4 mb-3" />
          <div className="text-pink-300 text-lg">{progress}%</div>
        </motion.div>
      )}

      {/* Thumbnails */}
      <div className="absolute bottom-8 w-full flex justify-center gap-4 z-10">
        {thumbs.map((img, i) => (
          <img
            key={i}
            src={img}
            className="w-20 h-20 object-cover rounded-full border-2 border-pink-400 shadow-md"
          />
        ))}
      </div>
    </div>
  );
}
