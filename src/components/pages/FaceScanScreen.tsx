import { useEffect, useRef, useState } from "react";
import { motion } from "motion/react";
import { Progress } from "../ui/progress";
import { X } from "lucide-react";
import { initFaceLandmarker, estimate, computeHeadPoseFromLandmarks } from "../../lib/pose";

interface FaceScanScreenProps {
  onAnalyzeResult: (result: any) => void; // ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß‡∏à‡∏≤‡∏Å backend
  onBack: () => void;
}

const STEPS = ["‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏á", "‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢", "‡∏´‡∏±‡∏ô‡∏Ç‡∏ß‡∏≤"] as const;
type Step = 0 | 1 | 2;

const STABLE_FRAMES = 8; // ‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡πà‡∏á‡∏Å‡∏µ‡πà‡πÄ‡∏ü‡∏£‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏ñ‡πà‡∏≤‡∏¢
const API_BASE = import.meta.env.VITE_API_BASE || "http://localhost:8000"; // ‚úÖ URL backend

export function FaceScanScreen({ onAnalyzeResult, onBack }: FaceScanScreenProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [step, setStep] = useState<Step>(0);
  const [thumbs, setThumbs] = useState<string[]>([]);
  const [status, setStatus] = useState("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...");
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [progress, setProgress] = useState(0);
  const stableCounter = useRef(0);
  const rafId = useRef<number>(0);

  useEffect(() => {
    (async () => {
      await initFaceLandmarker();
      await startCamera();
      setStatus(`üì∑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[0]}`);
      loop();
    })();
    return () => cancelAnimationFrame(rafId.current);
  }, []);

  async function startCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: "user" },
      audio: false,
    });
    if (videoRef.current) {
      videoRef.current.srcObject = stream;
      await videoRef.current.play();
    }
  }

  /** ‡πÅ‡∏õ‡∏•‡∏á frame ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô blob ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÑ‡∏õ backend */
  function captureFrame(): Promise<Blob> {
    return new Promise((resolve) => {
      const v = videoRef.current!;
      const c = document.createElement("canvas");
      c.width = v.videoWidth;
      c.height = v.videoHeight;
      const ctx = c.getContext("2d")!;
      ctx.drawImage(v, 0, 0, c.width, c.height);
      c.toBlob((blob) => blob && resolve(blob), "image/jpeg");
    });
  }

  /** ‡∏™‡πà‡∏á frame ‡πÑ‡∏õ‡πÉ‡∏´‡πâ backend ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏°‡∏∏‡∏° */
  async function checkPoseBackend(blob: Blob): Promise<string> {
    const formData = new FormData();
    formData.append("file", blob, "frame.jpg");
    const res = await fetch(`${API_BASE}/scan/pose`, { method: "POST", body: formData });
    const data = await res.json();
    return data.pose || "unknown";
  }

  /** ‡πÄ‡∏Å‡πá‡∏ö‡∏†‡∏≤‡∏û‡∏°‡∏∏‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏ß‡πâ */
  function captureThumb() {
    const v = videoRef.current!;
    const c = document.createElement("canvas");
    c.width = v.videoWidth;
    c.height = v.videoHeight;
    c.getContext("2d")!.drawImage(v, 0, 0, c.width, c.height);
    setThumbs((t) => [...t, c.toDataURL("image/jpeg")]);
  }

  /** ‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ */
  function nextStep() {
    if (step < 2) {
      const next = (step + 1) as Step;
      setStep(next);
      setStatus(`‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏ï‡πà‡∏≠‡πÑ‡∏õ: ${STEPS[next]}`);
      stableCounter.current = 0;
    } else {
      setStatus("üéâ ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 3 ‡∏°‡∏∏‡∏°‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...");
      startAnalyze();
    }
  }

  /** Loop ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå */
  async function loop() {
    const v = videoRef.current;
    if (!v) return;

    // ‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ backend ‡∏ï‡∏£‡∏ß‡∏à‡∏°‡∏∏‡∏°
    const blob = await captureFrame();
    const detectedPose = await checkPoseBackend(blob);

    const target = step === 0 ? "front" : step === 1 ? "left" : "right";

    if (detectedPose === target) {
      stableCounter.current++;
      setStatus(`‚úÖ ${STEPS[step]} ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏ô‡∏¥‡πà‡∏á‡∏≠‡∏µ‡∏Å ${STABLE_FRAMES - stableCounter.current})`);
      if (stableCounter.current >= STABLE_FRAMES) {
        captureThumb();
        nextStep();
      }
    } else if (detectedPose === "none") {
      setStatus("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ/‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á");
      stableCounter.current = 0;
    } else {
      stableCounter.current = 0;
      setStatus(`üü° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[step]}‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏° (${detectedPose})`);
    }

    rafId.current = requestAnimationFrame(loop);
  }

  /** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏£‡∏ö 3 ‡∏°‡∏∏‡∏°‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡∏™‡πà‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏´‡πâ backend ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß */
  async function startAnalyze() {
    setIsAnalyzing(true);
    setProgress(0);

    const blobs = await Promise.all(
      thumbs.map((t) =>
        fetch(t).then((r) => r.blob())
      )
    );

    const formData = new FormData();
    blobs.forEach((b) => formData.append("files", b, "angle.jpg"));

    const res = await fetch(`${API_BASE}/scan/analyze`, {
      method: "POST",
      body: formData,
    });
    const data = await res.json();

    // ‡πÇ‡∏´‡∏•‡∏î progress animation ‡∏™‡∏ß‡∏¢ ‡πÜ
    const timer = setInterval(() => {
      setProgress((p) => {
        if (p >= 100) {
          clearInterval(timer);
          onAnalyzeResult(data);
          return 100;
        }
        return p + 5;
      });
    }, 80);
  }

  return (
    <div className="min-h-screen bg-black relative overflow-hidden">
      {/* ‡∏õ‡∏∏‡πà‡∏°‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö */}
      <button
        onClick={onBack}
        className="absolute top-6 left-6 z-20 w-10 h-10 bg-black/30 rounded-full flex items-center justify-center"
      >
        <X className="w-6 h-6 text-white" />
      </button>

      {/* ‡∏Å‡∏•‡πâ‡∏≠‡∏á */}
      <video
        ref={videoRef}
        className="absolute inset-0 w-full h-full object-cover"
        autoPlay
        muted
        playsInline
      />

      {/* ‡∏ß‡∏á‡∏£‡∏µ‡∏à‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ */}
      <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
        <div
          className={`w-72 h-96 rounded-full border-4 transition-colors duration-150 ${
            status.startsWith("‚úÖ") || status.startsWith("üéâ")
              ? "border-green-400 shadow-[0_0_30px_rgba(34,197,94,0.7)]"
              : status.startsWith("üü°")
              ? "border-yellow-400 shadow-[0_0_30px_rgba(250,204,21,0.6)]"
              : "border-pink-400 shadow-[0_0_30px_rgba(244,114,182,0.6)]"
          }`}
        />
      </div>

      {/* ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ */}
      <motion.div
        className="absolute top-20 w-full text-center z-20 px-4"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
      >
        <div className="bg-black/60 text-white px-5 py-3 rounded-2xl inline-block text-lg font-medium">
          {status}
        </div>
      </motion.div>

      {/* ‡∏Å‡∏£‡∏ì‡∏µ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå */}
      {isAnalyzing && (
        <motion.div
          className="absolute inset-0 flex flex-col items-center justify-center bg-black/80 z-30"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
        >
          <div className="text-white mb-6 text-xl font-semibold">
            üî¨ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...
          </div>
          <Progress value={progress} className="h-3 w-3/4 mb-3" />
          <div className="text-pink-300 text-lg">{progress}%</div>
        </motion.div>
      )}

      {/* ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏î‡πâ */}
      <div className="absolute bottom-8 w-full flex justify-center gap-4 z-10">
        {thumbs.slice(0, 3).map((img, i) => (
          <img
            key={i}
            src={img}
            className="w-20 h-20 object-cover rounded-full border-2 border-pink-400 shadow-md"
          />
        ))}
      </div>
    </div>
  );
}
