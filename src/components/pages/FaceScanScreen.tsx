import { useEffect, useRef, useState } from "react";
import { motion } from "motion/react";
import { Progress } from "../ui/progress";
import { X } from "lucide-react";

// === Mediapipe FaceMesh ===
import { FaceMesh } from "@mediapipe/face_mesh";
import { Camera } from "@mediapipe/camera_utils";
import { drawConnectors, FACEMESH_CONTOURS } from "@mediapipe/drawing_utils";

// =========================================
// CONFIG
// =========================================
interface FaceScanScreenProps {
  onAnalyzeResult: (result: any) => void;
  onBack: () => void;
}

const STEPS = ["‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏£‡∏á", "‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢", "‡∏´‡∏±‡∏ô‡∏Ç‡∏ß‡∏≤"] as const;
type Step = 0 | 1 | 2;

const STABLE_TIME = 3000; // ‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡πà‡∏á 3 ‡∏ß‡∏¥
const NEXT_DELAY = 800; // ‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏∏‡∏°
const API_BASE =
  import.meta.env.VITE_API_BASE ||
  "https://aishincarebackend-production.up.railway.app";

// =========================================
// COMPONENT
// =========================================
export function FaceScanScreen({ onAnalyzeResult, onBack }: FaceScanScreenProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);

  const [step, setStep] = useState<Step>(0);
  const [thumbs, setThumbs] = useState<string[]>([]);
  const [status, setStatus] = useState("üì∑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á...");
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [progress, setProgress] = useState(0);
  const [stablePercent, setStablePercent] = useState(0);
  const [faceDetected, setFaceDetected] = useState(false);

  const startStableTime = useRef<number | null>(null);
  const stepLocked = useRef(false);

  // =========================================
  // üß† ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Mediapipe FaceMesh
  // =========================================
  useEffect(() => {
    const faceMesh = new FaceMesh({
      locateFile: (file) =>
        `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.6,
    });

    faceMesh.onResults(onResults);

    const camera = new Camera(videoRef.current!, {
      onFrame: async () => {
        await faceMesh.send({ image: videoRef.current! });
      },
      width: 640,
      height: 480,
    });
    camera.start();

    setStatus(`üì∑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[0]}`);
  }, []);

  // =========================================
  // üé® ‡∏ß‡∏≤‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏´‡∏ô‡πâ‡∏≤ + ‡∏ï‡∏£‡∏ß‡∏à‡∏°‡∏∏‡∏°
  // =========================================
  function onResults(results: any) {
    const canvas = canvasRef.current!;
    const ctx = canvas.getContext("2d")!;
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
      setFaceDetected(true);
      const landmarks = results.multiFaceLandmarks[0];

      // ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤
      drawConnectors(ctx, landmarks, FACEMESH_CONTOURS, {
        color: "rgba(255,105,180,0.9)",
        lineWidth: 1.5,
      });

      // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°
      const left = landmarks[234];
      const right = landmarks[454];
      const nose = landmarks[1];
      const ratio = (nose.x - left.x) / (right.x - left.x);

      let pose = "front";
      if (ratio < 0.35) pose = "left";
      else if (ratio > 0.65) pose = "right";

      const target = step === 0 ? "front" : step === 1 ? "left" : "right";

      if (pose === target) {
        if (!startStableTime.current) startStableTime.current = Date.now();
        const elapsed = Date.now() - startStableTime.current;
        const percent = Math.min((elapsed / STABLE_TIME) * 100, 100);
        setStablePercent(percent);
        setStatus(`‚úÖ ${STEPS[step]} ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (${(elapsed / 1000).toFixed(1)}s / 3s)`);

        if (elapsed >= STABLE_TIME && !stepLocked.current) {
          stepLocked.current = true;
          captureThumb();
          setStablePercent(0);
          setStatus(`üì∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏°‡∏∏‡∏° ${STEPS[step]} ‡πÅ‡∏•‡πâ‡∏ß!`);

          setTimeout(() => {
            handleNextStep();
          }, 1000);
        }
      } else {
        startStableTime.current = null;
        setStablePercent(0);
        setStatus(`üü° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[step]}‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏°`);
      }
    } else {
      setFaceDetected(false);
      setStatus("üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á");
      startStableTime.current = null;
      setStablePercent(0);
    }
  }

  // =========================================
  // ‚è≠Ô∏è ‡πÑ‡∏õ‡∏°‡∏∏‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ
  // =========================================
  async function handleNextStep() {
    if (step < 2) {
      const next = (step + 1) as Step;
      setStep(next);
      setStatus(`üü° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤${STEPS[next]}‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏°‡∏∏‡∏°`);
      startStableTime.current = null;
      setStablePercent(0);
      stepLocked.current = false;
    } else {
      setStatus("üéâ ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 3 ‡∏°‡∏∏‡∏°‡πÅ‡∏•‡πâ‡∏ß! ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß...");
      startAnalyze();
    }
  }

  // =========================================
  // üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
  // =========================================
  function captureThumb() {
    const v = videoRef.current!;
    const c = document.createElement("canvas");
    c.width = v.videoWidth;
    c.height = v.videoHeight;
    const ctx = c.getContext("2d")!;
    ctx.translate(c.width, 0);
    ctx.scale(-1, 1);
    ctx.drawImage(v, 0, 0, c.width, c.height);
    setThumbs((t) => [...t, c.toDataURL("image/jpeg")]);
  }

  // =========================================
  // üî¨ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß
  // =========================================
  async function startAnalyze() {
    setIsAnalyzing(true);
    const blobs = await Promise.all(
      thumbs.map((t) => fetch(t).then((r) => r.blob()))
    );
    const formData = new FormData();
    blobs.forEach((b, i) => formData.append("files", b, `angle_${i}.jpg`));

    const res = await fetch(`${API_BASE}/analyze/skin`, {
      method: "POST",
      body: formData,
    });
    const data = await res.json();

    let p = 0;
    const timer = setInterval(() => {
      p += 5;
      setProgress(p);
      if (p >= 100) {
        clearInterval(timer);
        onAnalyzeResult(data);
      }
    }, 80);
  }

  // =========================================
  // UI
  // =========================================
  return (
    <div className="min-h-screen bg-black relative overflow-hidden">
      {/* Back */}
      <button
        onClick={onBack}
        className="absolute top-6 left-6 z-20 w-10 h-10 bg-black/30 rounded-full flex items-center justify-center"
      >
        <X className="w-6 h-6 text-white" />
      </button>

      {/* Camera */}
      <video
        ref={videoRef}
        className="absolute inset-0 w-full h-full object-cover transform -scale-x-100"
        autoPlay
        muted
        playsInline
      />
      <canvas
        ref={canvasRef}
        width={640}
        height={480}
        className="absolute inset-0 w-full h-full pointer-events-none"
        style={{ filter: "drop-shadow(0 0 10px rgba(255,105,180,0.7))" }}
      />

      {/* Status */}
      <motion.div
        className="absolute top-20 w-full text-center z-20 px-4"
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
      >
        <div className="bg-black/60 text-white px-5 py-3 rounded-2xl inline-block text-lg font-medium">
          {status}
        </div>
      </motion.div>

      {/* Stable Progress */}
      {!isAnalyzing && stablePercent > 0 && (
        <div className="absolute bottom-24 w-full flex justify-center z-20">
          <div className="w-2/3">
            <Progress value={stablePercent} className="h-2" />
          </div>
        </div>
      )}

      {/* Analyze Overlay */}
      {isAnalyzing && (
        <motion.div
          className="absolute inset-0 flex flex-col items-center justify-center bg-black/80 z-30"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
        >
          <div className="text-white mb-6 text-xl font-semibold">
            üî¨ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...
          </div>
          <Progress value={progress} className="h-3 w-3/4 mb-3" />
          <div className="text-pink-300 text-lg">{progress}%</div>
        </motion.div>
      )}

      {/* Thumbnails */}
      <div className="absolute bottom-8 w-full flex justify-center gap-4 z-10">
        {thumbs.map((img, i) => (
          <img
            key={i}
            src={img}
            className="w-20 h-20 object-cover rounded-full border-2 border-pink-400 shadow-md"
          />
        ))}
      </div>
    </div>
  );
}
